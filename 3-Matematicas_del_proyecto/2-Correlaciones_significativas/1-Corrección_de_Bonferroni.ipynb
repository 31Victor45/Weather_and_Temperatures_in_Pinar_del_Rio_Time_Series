{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540d35b1",
   "metadata": {},
   "source": [
    "# La Correcci√≥n de Bonferroni: Controlando el Error Familiar üõ°Ô∏è\n",
    "\n",
    "---\n",
    "\n",
    "## **# 1. El Problema: Inflaci√≥n del Error Tipo I ($\\alpha$)**\n",
    "\n",
    "En la estad√≠stica de series de tiempo y en la ciencia de datos en general, a menudo necesitamos realizar **m√∫ltiples pruebas de hip√≥tesis** simult√°neamente. Por ejemplo:\n",
    "* Correr la **prueba de Ljung-Box** para la no autocorrelaci√≥n de residuos en 10, 20 o 30 *lags* diferentes.\n",
    "* Comparar la media de ventas entre 50 tiendas distintas (50 comparaciones).\n",
    "* Probar la significancia de 100 *features* diferentes en un modelo.\n",
    "\n",
    "### **El Riesgo del Error Tipo I (Falso Positivo)**\n",
    "\n",
    "Recordemos que el **Error Tipo I** ($\\alpha$) es la probabilidad de **rechazar la Hip√≥tesis Nula ($H_0$) cuando en realidad es verdadera**. Generalmente fijamos este nivel en $\\alpha = 0.05$ (o 5%).\n",
    "\n",
    "Cuando realizamos **solo una prueba**, la probabilidad de cometer un falso positivo es del 5%.\n",
    "\n",
    "Cuando realizamos **$m$ pruebas independientes**, la probabilidad de cometer *al menos un* Falso Positivo se dispara. Esto se conoce como la **Tasa de Error Familiar** (*Family-Wise Error Rate*, FWER).\n",
    "\n",
    "### **F√≥rmula del Error Familiar (FWER)**\n",
    "\n",
    "Si realizamos $m$ pruebas con un nivel de significancia individual $\\alpha$, la probabilidad de cometer **al menos un Error Tipo I** es:\n",
    "\n",
    "$$\n",
    "\\text{FWER} = 1 - (1 - \\alpha)^m\n",
    "$$\n",
    "\n",
    "| N√∫mero de Pruebas ($m$) | $\\alpha = 0.05$ | FWER (Riesgo real) |\n",
    "| :--- | :--- | :--- |\n",
    "| 1 | 0.05 | 5.0% |\n",
    "| 5 | 0.05 | 22.6% |\n",
    "| 20 | 0.05 | **64.2%** |\n",
    "\n",
    "**Conclusi√≥n:** Si realizamos 20 pruebas de Ljung-Box con $\\alpha=0.05$, tenemos m√°s del 64% de probabilidad de declarar err√≥neamente que **al menos uno** de esos *lags* es significativo, incluso si no lo es (un falso positivo).\n",
    "\n",
    "---\n",
    "\n",
    "## **# 2. La Correcci√≥n de Bonferroni**\n",
    "\n",
    "La Correcci√≥n de Bonferroni es el m√©todo m√°s simple y conservador para controlar la Tasa de Error Familiar (FWER).\n",
    "\n",
    "El m√©todo ajusta el nivel de significancia individual ($\\alpha_{individual}$) para garantizar que la FWER total de todo el \"experimento familiar\" sea menor o igual al nivel de significancia deseado (ej. 0.05).\n",
    "\n",
    "### **F√≥rmula de Bonferroni (El Nivel $\\alpha$ Ajustado)**\n",
    "\n",
    "Para mantener una FWER total de $\\alpha_{deseado}$ al realizar $m$ pruebas, el nuevo nivel de significancia para **cada prueba individual** es:\n",
    "\n",
    "$$\n",
    "\\alpha_{\\text{Bonferroni}} = \\frac{\\alpha_{\\text{deseado}}}{m}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "* $\\alpha_{\\text{deseado}}$: El nivel de significancia que quieres para todo el experimento (ej. 0.05).\n",
    "* $m$: El n√∫mero total de pruebas realizadas.\n",
    "* $\\alpha_{\\text{Bonferroni}}$: El nuevo *p-valor umbral* que deben superar tus resultados.\n",
    "\n",
    "### **Ejemplo Num√©rico**\n",
    "\n",
    "Si quieres que tu **FWER** sea 0.05 y realizas $m=20$ pruebas:\n",
    "\n",
    "$$\n",
    "\\alpha_{\\text{Bonferroni}} = \\frac{0.05}{20} = 0.0025\n",
    "$$\n",
    "\n",
    "**Regla de Decisi√≥n Ajustada:**\n",
    "* Solo rechazar√°s la Hip√≥tesis Nula ($H_0$) de una prueba si su p-valor es **menor que $0.0025$** (en lugar de $0.05$).\n",
    "\n",
    "---\n",
    "\n",
    "## **# 3. Importancia y Limitaciones**\n",
    "\n",
    "### **Importancia (Por qu√© la usamos)**\n",
    "\n",
    "* **Control del FWER:** Garantiza que la probabilidad de encontrar *alg√∫n* falso positivo en tu conjunto de pruebas se mantenga en el nivel deseado (ej. 5%).\n",
    "* **Simplicidad:** Es muy f√°cil de calcular e implementar.\n",
    "* **Robustez:** Es universalmente aplicable, independientemente de si las pruebas son dependientes o independientes.\n",
    "\n",
    "### **Limitaciones (El Trade-off del Cient√≠fico de Datos)**\n",
    "\n",
    "La Correcci√≥n de Bonferroni es famosa por ser **demasiado conservadora**.\n",
    "\n",
    "1.  **Aumento del Error Tipo II ($\\beta$):** Al reducir dr√°sticamente el umbral $\\alpha$ (de 0.05 a 0.0025, por ejemplo), se hace mucho m√°s dif√≠cil rechazar $H_0$. Esto aumenta la probabilidad de cometer un **Error Tipo II** (*False Negative*): **aceptar $H_0$ cuando en realidad es falsa** (perderte un patr√≥n o una diferencia real).\n",
    "2.  **Modelos Alternativos:** Debido a esta conservatividad, en la pr√°ctica profesional a menudo se prefieren m√©todos menos estrictos pero m√°s potentes (que tienen un mejor equilibrio entre el Error Tipo I y el Tipo II), como el m√©todo de **Benjamini-Hochberg (BH)**, que controla la **Tasa de Descubrimiento Falso** (*False Discovery Rate*, FDR) en lugar del FWER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d075df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de pruebas (m): 10\n",
      "Nivel de significancia ajustado (alfa_bonferroni): 0.0050\n",
      "\n",
      "--- Resultados ---\n",
      "Lag 1: p-valor=0.0450\n",
      "  > Normal (0.05): RECHAZA H0 (Significativo)\n",
      "  > Bonferroni (0.0050): NO RECHAZA H0\n",
      "Lag 2: p-valor=0.0030\n",
      "  > Normal (0.05): RECHAZA H0 (Significativo)\n",
      "  > Bonferroni (0.0050): RECHAZA H0 (Significativo)\n",
      "Lag 3: p-valor=0.0010\n",
      "  > Normal (0.05): RECHAZA H0 (Significativo)\n",
      "  > Bonferroni (0.0050): RECHAZA H0 (Significativo)\n",
      "Lag 4: p-valor=0.1500\n",
      "  > Normal (0.05): NO RECHAZA H0\n",
      "  > Bonferroni (0.0050): NO RECHAZA H0\n",
      "Lag 5: p-valor=0.0020\n",
      "  > Normal (0.05): RECHAZA H0 (Significativo)\n",
      "  > Bonferroni (0.0050): RECHAZA H0 (Significativo)\n",
      "Lag 6: p-valor=0.0600\n",
      "  > Normal (0.05): NO RECHAZA H0\n",
      "  > Bonferroni (0.0050): NO RECHAZA H0\n",
      "Lag 7: p-valor=0.0480\n",
      "  > Normal (0.05): RECHAZA H0 (Significativo)\n",
      "  > Bonferroni (0.0050): NO RECHAZA H0\n",
      "Lag 8: p-valor=0.0005\n",
      "  > Normal (0.05): RECHAZA H0 (Significativo)\n",
      "  > Bonferroni (0.0050): RECHAZA H0 (Significativo)\n",
      "Lag 9: p-valor=0.2000\n",
      "  > Normal (0.05): NO RECHAZA H0\n",
      "  > Bonferroni (0.0050): NO RECHAZA H0\n",
      "Lag 10: p-valor=0.3000\n",
      "  > Normal (0.05): NO RECHAZA H0\n",
      "  > Bonferroni (0.0050): NO RECHAZA H0\n",
      "\n",
      "--- Efecto del Ajuste ---\n",
      "Total de significativos (Normal): 6\n",
      "Total de significativos (Bonferroni): 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Par√°metros del experimento\n",
    "alfa_deseado = 0.05  # Nivel de significancia del 5% para todo el 'experimento'\n",
    "m_pruebas = 10       # N√∫mero de lags que probamos en el Ljung-Box\n",
    "\n",
    "# 2. Calcular el umbral de Bonferroni\n",
    "alfa_bonferroni = alfa_deseado / m_pruebas\n",
    "\n",
    "print(f\"N√∫mero de pruebas (m): {m_pruebas}\")\n",
    "print(f\"Nivel de significancia ajustado (alfa_bonferroni): {alfa_bonferroni:.4f}\")\n",
    "\n",
    "# 3. Datos de ejemplo: p-valores de 10 pruebas de Ljung-Box (simulados)\n",
    "p_valores_simulados = np.array([0.045, 0.003, 0.001, 0.150, 0.002, 0.060, 0.048, 0.0005, 0.200, 0.300])\n",
    "\n",
    "print(\"\\n--- Resultados ---\")\n",
    "\n",
    "for i, p_val in enumerate(p_valores_simulados):\n",
    "    es_significativo_bonf = p_val < alfa_bonferroni\n",
    "    es_significativo_normal = p_val < alfa_deseado\n",
    "    \n",
    "    # Decisi√≥n normal (riesgo alto de Falso Positivo)\n",
    "    decision_normal = \"RECHAZA H0 (Significativo)\" if es_significativo_normal else \"NO RECHAZA H0\"\n",
    "    \n",
    "    # Decisi√≥n Bonferroni (controlando FWER)\n",
    "    decision_bonf = \"RECHAZA H0 (Significativo)\" if es_significativo_bonf else \"NO RECHAZA H0\"\n",
    "    \n",
    "    print(f\"Lag {i+1}: p-valor={p_val:.4f}\")\n",
    "    print(f\"  > Normal (0.05): {decision_normal}\")\n",
    "    print(f\"  > Bonferroni ({alfa_bonferroni:.4f}): {decision_bonf}\")\n",
    "\n",
    "# RESUMEN DEL EFECTO\n",
    "print(\"\\n--- Efecto del Ajuste ---\")\n",
    "print(f\"Total de significativos (Normal): {sum(p_valores_simulados < alfa_deseado)}\")\n",
    "print(f\"Total de significativos (Bonferroni): {sum(p_valores_simulados < alfa_bonferroni)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
