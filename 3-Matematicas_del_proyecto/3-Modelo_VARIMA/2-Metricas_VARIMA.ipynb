{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5585fbd8",
   "metadata": {},
   "source": [
    "# üìä M√©tricas de Evaluaci√≥n para Modelos VARIMA/VAR\n",
    "\n",
    "Una vez que un modelo VARIMA (o su versi√≥n m√°s com√∫n, el VAR) ha sido estimado y utilizado para generar pron√≥sticos, es crucial evaluar su rendimiento. A diferencia de la regresi√≥n lineal simple, los modelos de series de tiempo requieren m√©tricas que penalicen los errores a lo largo de un horizonte temporal.\n",
    "\n",
    "## 1. üìù Fundamentos de la Evaluaci√≥n de Pron√≥sticos\n",
    "\n",
    "En el contexto multivariado del VARIMA (donde se pronostican $K$ series simult√°neamente), las m√©tricas se aplican generalmente a los errores de pron√≥stico de **cada serie** individualmente.\n",
    "\n",
    "$$\n",
    "\\text{Error de Pron√≥stico} (e_{i, t}) = \\text{Valor Real} (y_{i, t}) - \\text{Valor Pronosticado} (\\hat{y}_{i, t})\n",
    "$$\n",
    "\n",
    "Donde $i$ es la serie (e.g., $Y$ o $X$) y $t$ es el punto en el tiempo.\n",
    "\n",
    "## 2. üéØ M√©tricas Basadas en el Error Absoluto\n",
    "\n",
    "Estas m√©tricas son las m√°s f√°ciles de interpretar, ya que est√°n en las mismas unidades que la serie original.\n",
    "\n",
    "### A. Error Absoluto Medio (MAE - Mean Absolute Error)\n",
    "\n",
    "El MAE es la media de la magnitud de los errores en el conjunto de prueba.\n",
    "\n",
    "* **F√≥rmula:** Mide la desviaci√≥n promedio.\n",
    "    $$\n",
    "    \\text{MAE} = \\frac{1}{N} \\sum_{t=1}^{N} |e_{t}| = \\frac{1}{N} \\sum_{t=1}^{N} |y_{t} - \\hat{y}_{t}|\n",
    "    $$\n",
    "* **Ventaja:** No penaliza los errores grandes tan severamente como el RMSE.\n",
    "* **Interpretaci√≥n:** Un MAE de 5 significa que, en promedio, el pron√≥stico est√° desviado en 5 unidades de la serie original.\n",
    "\n",
    "### B. Error Cuadr√°tico Medio de la Ra√≠z (RMSE - Root Mean Squared Error)\n",
    "\n",
    "El RMSE es la m√©trica m√°s utilizada. Mide la desviaci√≥n est√°ndar de los residuos (errores de predicci√≥n).\n",
    "\n",
    "* **F√≥rmula:** Se calcula la ra√≠z cuadrada de la media de los errores al cuadrado.\n",
    "    $$\n",
    "    \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{t=1}^{N} e_{t}^2} = \\sqrt{\\frac{1}{N} \\sum_{t=1}^{N} (y_{t} - \\hat{y}_{t})^2}\n",
    "    $$\n",
    "* **Ventaja:** Penaliza fuertemente los errores grandes (outliers), lo que lo hace √∫til cuando los grandes errores son particularmente indeseables (e.g., en la gesti√≥n de riesgos).\n",
    "* **Desventaja:** Al estar en las unidades de la serie, es dif√≠cil comparar modelos entre diferentes series con distintas escalas.\n",
    "\n",
    "## 3. üéØ M√©tricas Basadas en el Error Porcentual\n",
    "\n",
    "Estas m√©tricas son √∫tiles para comparar la precisi√≥n de los pron√≥sticos en diferentes series con diferentes escalas.\n",
    "\n",
    "### A. Error Porcentual Absoluto Medio (MAPE - Mean Absolute Percentage Error)\n",
    "\n",
    "El MAPE expresa la precisi√≥n como un porcentaje. Es intuitivo para los no expertos.\n",
    "\n",
    "* **F√≥rmula:**\n",
    "    $$\n",
    "    \\text{MAPE} = \\frac{100\\%}{N} \\sum_{t=1}^{N} \\left| \\frac{y_{t} - \\hat{y}_{t}}{y_{t}} \\right|\n",
    "    $$\n",
    "* **Interpretaci√≥n:** Un MAPE de 10% significa que el error de pron√≥stico promedio es del 10%.\n",
    "* **Desventaja Cr√≠tica:** Se vuelve infinito o indefinido si el valor real ($y_t$) es cero o muy cercano a cero (un problema com√∫n en series de retornos financieros o cambios de variables).\n",
    "\n",
    "### B. Error Porcentual Absoluto Escalonado Medio (MASE - Mean Absolute Scaled Error)\n",
    "\n",
    "El MASE es una m√©trica relativamente nueva y robusta que compara el error del modelo con el error de un pron√≥stico ingenuo (Naive Forecast) para la misma serie.\n",
    "\n",
    "* **F√≥rmula:** (El denominador es el error del pron√≥stico ingenuo del paso anterior, $y_{t} - y_{t-1}$)\n",
    "    $$\n",
    "    \\text{MASE} = \\frac{\\frac{1}{N} \\sum_{t=1}^{N} |y_{t} - \\hat{y}_{t}|}{\\frac{1}{N-1} \\sum_{t=2}^{N} |y_{t} - y_{t-1}|}\n",
    "    $$\n",
    "* **Ventaja Principal:** Es independiente de la escala y es robusto ante valores de cero ($y_t=0$).\n",
    "* **Interpretaci√≥n Clave:**\n",
    "    * **MASE < 1:** El modelo VARIMA es mejor que el pron√≥stico ingenuo (bueno).\n",
    "    * **MASE = 1:** El modelo VARIMA es tan bueno como el pron√≥stico ingenuo.\n",
    "    * **MASE > 1:** El modelo VARIMA es peor que el pron√≥stico ingenuo (malo).\n",
    "\n",
    "## 4. üêç C√≥digo Python (Jupyter Notebook)\n",
    "\n",
    "Este c√≥digo muestra c√≥mo calcular estas cuatro m√©tricas clave utilizando los pron√≥sticos generados por un modelo VAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a305ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo VAR(8) ajustado y pron√≥stico generado para 100 pasos.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìä Resultados de las M√©tricas de Evaluaci√≥n del Pron√≥stico (Modelo VAR)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_42120\">\n",
       "  <caption>M√©tricas de Pron√≥stico por Serie</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_42120_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_42120_level0_col1\" class=\"col_heading level0 col1\" >RMSE</th>\n",
       "      <th id=\"T_42120_level0_col2\" class=\"col_heading level0 col2\" >MAPE (%)</th>\n",
       "      <th id=\"T_42120_level0_col3\" class=\"col_heading level0 col3\" >MASE (<1 es mejor)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Serie</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_42120_level0_row0\" class=\"row_heading level0 row0\" >Y</th>\n",
       "      <td id=\"T_42120_row0_col0\" class=\"data row0 col0\" >10542088421146373446107698038437659489721237458113719662234324338240126976.0000</td>\n",
       "      <td id=\"T_42120_row0_col1\" class=\"data row0 col1\" >48267007678458888947065695023329965014989538414635194021106331667212009472.0000</td>\n",
       "      <td id=\"T_42120_row0_col2\" class=\"data row0 col2\" >0.00</td>\n",
       "      <td id=\"T_42120_row0_col3\" class=\"data row0 col3\" >1111610.1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42120_level0_row1\" class=\"row_heading level0 row1\" >X</th>\n",
       "      <td id=\"T_42120_row1_col0\" class=\"data row1 col0\" >1640225453304852880750735729066410422382759428943817992288175830887038976.0000</td>\n",
       "      <td id=\"T_42120_row1_col1\" class=\"data row1 col1\" >7499082141528089771794712084960994254510335842615666966686948247400873984.0000</td>\n",
       "      <td id=\"T_42120_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_42120_row1_col3\" class=\"data row1 col3\" >1496713.4933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29ea0c82d80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Interpretaci√≥n del MASE (Conclusi√≥n del Modelo)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**MASE de Y:** `1111610.1506`. \n",
       "\n",
       "**MASE de X:** `1496713.4933`. \n",
       "\n",
       "**Conclusi√≥n:** En nuestro ejemplo, ambos valores de MASE son extremadamente altos ($>> 1$). Esto significa que el modelo **VAR(8)** es significativamente **peor** que un simple pron√≥stico ingenuo ($Y_t = Y_{t-1}$) para estas series. Esto era esperado ya que la data sint√©tica era altamente no estacionaria y el modelo VAR(8) no logr√≥ capturar la estructura subyacente de manera efectiva."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.api import VAR\n",
    "from IPython.display import display, HTML, Markdown # <--- IMPORTANTE: Nuevas importaciones para una salida limpia\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Definici√≥n de Funciones de M√©trica ---\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    \"\"\"Calcula el Error Porcentual Absoluto Medio (MAPE).\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Evitar divisi√≥n por cero o valores cercanos\n",
    "    nonzero_mask = y_true != 0\n",
    "    if not np.any(nonzero_mask):\n",
    "         return np.nan\n",
    "         \n",
    "    return np.mean(np.abs((y_true[nonzero_mask] - y_pred[nonzero_mask]) / y_true[nonzero_mask])) * 100\n",
    "\n",
    "def calculate_mase(y_true, y_pred, y_train):\n",
    "    \"\"\"Calcula el Error Porcentual Absoluto Escalonado Medio (MASE).\"\"\"\n",
    "    # Denominador: Error Absoluto Medio del Pron√≥stico Naive (Naive MAE)\n",
    "    naive_mae = np.mean(np.abs(y_train[1:] - y_train[:-1]))\n",
    "    \n",
    "    if naive_mae == 0:\n",
    "        return np.inf # MASE es infinito si el pron√≥stico ingenuo es perfecto\n",
    "        \n",
    "    # Numerador: MAE del modelo sobre el conjunto de prueba\n",
    "    model_mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return model_mae / naive_mae\n",
    "\n",
    "# --- 2. Preparaci√≥n de Data de Prueba y Pron√≥stico ---\n",
    "\n",
    "# Generaci√≥n de series (mismos par√°metros altamente no estacionarios)\n",
    "np.random.seed(42)\n",
    "N = 500\n",
    "X, Y = np.zeros(N), np.zeros(N)\n",
    "ruido_x, ruido_y = np.random.normal(0, 1, N), np.random.normal(0, 1, N)\n",
    "for t in range(1, N):\n",
    "    X[t] = X[t-1] + 0.5 * X[t-1] + ruido_x[t] * 0.1 \n",
    "    Y[t] = Y[t-1] + 0.5 * Y[t-1] + 0.3 * X[t-1] * 0.1 + ruido_y[t] * 0.1\n",
    "\n",
    "# Usamos primeras diferencias\n",
    "df_var = pd.DataFrame({'Y': Y, 'X': X}).diff().dropna()\n",
    "\n",
    "# Divisi√≥n en entrenamiento (Train) y prueba (Test)\n",
    "train_size = int(len(df_var) * 0.8)\n",
    "data_train = df_var.iloc[:train_size]\n",
    "data_test = df_var.iloc[train_size:]\n",
    "\n",
    "# --- 3. Ajuste y Pron√≥stico del Modelo VAR ---\n",
    "\n",
    "optimal_lag = 8 \n",
    "model = VAR(data_train).fit(optimal_lag)\n",
    "\n",
    "lag_order = model.k_ar\n",
    "last_observations = data_train.values[-lag_order:]\n",
    "forecast_steps = len(data_test)\n",
    "\n",
    "forecast_values = model.forecast(last_observations, steps=forecast_steps)\n",
    "forecast_df = pd.DataFrame(forecast_values, columns=['Y_pred', 'X_pred'], index=data_test.index)\n",
    "\n",
    "print(f\"‚úÖ Modelo VAR({optimal_lag}) ajustado y pron√≥stico generado para {forecast_steps} pasos.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 4. C√°lculo y PRESENTACI√ìN MEJORADA de M√©tricas ---\n",
    "\n",
    "results = {}\n",
    "\n",
    "for series_name in ['Y', 'X']:\n",
    "    y_true = data_test[series_name].values\n",
    "    y_pred = forecast_df[f'{series_name}_pred'].values\n",
    "    y_train = data_train[series_name].values\n",
    "\n",
    "    # Calcular M√©tricas\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = calculate_mape(y_true, y_pred)\n",
    "    mase = calculate_mase(y_true, y_pred, y_train)\n",
    "\n",
    "    # Almacenar los resultados como FLOATS (no strings) para formatear la tabla despu√©s\n",
    "    results[series_name] = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE (%)': mape,\n",
    "        'MASE (<1 es mejor)': mase\n",
    "    }\n",
    "\n",
    "# Convertir el diccionario a DataFrame\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df.index.name = 'Serie'\n",
    "\n",
    "# --- PRESENTACI√ìN FINAL LIMPIA USANDO DISPLAY ---\n",
    "\n",
    "display(Markdown(\"## üìä Resultados de las M√©tricas de Evaluaci√≥n del Pron√≥stico (Modelo VAR)\"))\n",
    "\n",
    "# Formatear el DataFrame para que los n√∫meros grandes se vean limpios\n",
    "styled_table = metrics_df.style.format({\n",
    "    'MAE': \"{:.4f}\",\n",
    "    'RMSE': \"{:.4f}\",\n",
    "    'MAPE (%)': \"{:.2f}\",\n",
    "    'MASE (<1 es mejor)': \"{:.4f}\"\n",
    "}).set_caption(\"M√©tricas de Pron√≥stico por Serie\")\n",
    "\n",
    "# Mostrar la tabla formateada (usa HTML internamente)\n",
    "display(styled_table)\n",
    "\n",
    "display(Markdown(\"\\n### Interpretaci√≥n del MASE (Conclusi√≥n del Modelo)\"))\n",
    "display(Markdown(\n",
    "    f\"**MASE de Y:** `{metrics_df.loc['Y', 'MASE (<1 es mejor)']:.4f}`. \\n\\n\"\n",
    "    f\"**MASE de X:** `{metrics_df.loc['X', 'MASE (<1 es mejor)']:.4f}`. \\n\\n\"\n",
    "    \"**Conclusi√≥n:** En nuestro ejemplo, ambos valores de MASE son extremadamente altos ($>> 1$). Esto significa que el modelo **VAR(8)** es significativamente **peor** que un simple pron√≥stico ingenuo ($Y_t = Y_{t-1}$) para estas series. Esto era esperado ya que la data sint√©tica era altamente no estacionaria y el modelo VAR(8) no logr√≥ capturar la estructura subyacente de manera efectiva.\"\n",
    "))\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
